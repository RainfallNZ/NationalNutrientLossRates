---
title: "R Notebook"
output: html_notebook
---

Load libraries and external functions

```{r}
if (!require(sf)) install.packages("sf"); library(sf)
if (!require(plyr)) install.packages("plyr"); library(plyr)
if (!require(dplyr)) install.packages("dplyr"); library(dplyr)
if (!require(pbapply)) install.packages("pbapply"); library(pbapply)
if (!require(terra)) install.packages("terra"); library(terra)
if (!require(tidyr)) install.packages("tidyr"); library(tidyr)

source("ProcessingFunctions.R")
```

Set Directories and file names
```{r}

ProjectDirectory <- "D:\\Projects\\LWP\\OLW_AttenuationUncertainty"
ProjectDataDirectory <- file.path(ProjectDirectory,"Data")
GISDirectory <- file.path(ProjectDataDirectory,"GIS")

LeachRateLUTFile <- file.path(ProjectDataDirectory,"LandUseToLossRatesV0.csv")

```

Create default Catchment-scale and Farm-scale grids that cover the country.
CAtchment scales grid are 10 km x 10 km squares with the bottom left hand corner at
NZTM coordinate Easting=1000000 Northing=4700000
Topright at Easting=2100000, Northing=6200000
```{r}
ExtentCoordinates <- data.frame("Easting"=c(1000000,2100000),"Northing"=c(4700000,6200000))
ExtentPolygon <- ExtentCoordinates %>% 
  st_as_sf(coords = c("Easting","Northing"),crs= "epsg:2193") %>%
  st_bbox() %>%
  st_as_sfc()

CatchmentScaleResolution <- 10000
CatchmentScaleGrid <- rast(vect(ExtentPolygon),resolution = CatchmentScaleResolution)

CatchmentScalePolygonGrid <-sf::st_as_sf(st_make_grid(vect(ExtentPolygon), 
                                          cellsize = CatchmentScaleResolution))

#This next line gets the centroid coordinates of each polygon, subtracts the bottom left coordinates and half the cell resolution, converts them to km, and and adds 1 (to keep indexing from 1) and converts to a fixed width format
NumericIDs <- st_centroid(st_geometry(CatchmentScalePolygonGrid)) %>% st_coordinates() %>% as.data.frame() %>% mutate(across(1,~((. - ExtentCoordinates$Easting[1] - CatchmentScaleResolution/2) / 10000 + 1))) %>% 
  mutate(across(2,~((. - ExtentCoordinates$Northing[1] - CatchmentScaleResolution/2) / 10000 + 1))) %>% 
  mutate_all(~sprintf("%03g",.))

CatchmentScalePolygonGrid$CSID <- paste0("CS",apply(NumericIDs,1,paste,collapse=""))

CatchmentScalePolygonGrid %>% st_write(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "CatchmentScaleGrid", delete_layer = TRUE)
```


Create the catchment polygon shape files for the water quality observation locations
```{r,eval = FALSE}
#Load the watershed and river network data. Note that these are large.
#The RECV2 geodatabase. version  from Ton with correct attribute names.
REC2V2GeoDatabase <- "D:\\Projects\\data\\RECV2.5\\nzRec2_v5.gdb" #This is the NIWA version

RiverNetwork <- sf::st_read(REC2V2GeoDatabase, layer = "riverlines")
Watersheds <- sf::st_read(REC2V2GeoDatabase, layer = "rec2ws")

#Load the Site data. Provided by Ton as RData files. One for TN and one for TP, but 
# both load a data frame called "BestLoads", and both (supposedly) with the same reach ID's
load(file.path(ProjectDataDirectory,"BestTNloads_22May17_y2020.rdata"))
Locations <- BestLoads$nzsegment
names(Locations) <- BestLoads$sID

remove(BestLoads)

CatchmentList <- pblapply(Locations, function(Location) {
  Catchment <- CatchmentCreator(Watersheds = Watersheds, ReachNetwork = RiverNetwork, OutletReach = Location)
  return(Catchment)
})
Catchments <- do.call(rbind,CatchmentList)
Catchments$sID <- names(CatchmentList)
st_write(Catchments,dsn = file.path(GISDirectory,"Catchments"),driver = "ESRI Shapefile",append = FALSE)


#Clear out some space
remove("BestLoads","RiverNetwork","Watersheds")

#Plot the result as a check it is right
plot(st_geometry(Catchments))
```


Reclass the LCDBV5 and save
```{r,eval = FALSE}
#Takes 90 minutes!
Start_time = Sys.time()

#The LCDBV5 geodatabase. version  from downloaded from LRIS 
LCDBV5GeoDatabase <- "D:\\Projects\\data\\LCDBV5\\lcdb-v50-land-cover-database-version-50-mainland-new-zealand.gdb"

#This takes ~1 minute to load and gives a warning that can be ignored
LCDBV5 <- sf::st_read(LCDBV5GeoDatabase)

#The Dairy areas
MonaghanGeoDatabase <- "D:\\Projects\\data\\OLWNutrientExportSpatialFiles\\Export_MfE.gdb"

#Load the dairy areas, and union into a single MultiPolygon, this takes time...30 s
MonaghanDairy <- sf::st_read(MonaghanGeoDatabase,layer = "TypologiesDairy") %>% st_union()

#Give it a "Dairy" attribute set to TRUE
Dairy <- data.frame(Dairy = TRUE)
st_geometry(Dairy) <- MonaghanDairy

#Load the LCDBV5-to-Srinivasan reclass table
LandUseLookupTable <- read.csv(file.path(ProjectDataDirectory,"LCDBV5ReclassTable.csv"))

#And reclass the LCDBV5
ReclassedLCDBV5 <- merge(LCDBV5,LandUseLookupTable[,c("Class_2018","SrinivasanLandUse")],all.x=TRUE)

#dissolve the polygons
ReclassedLCDBV5 <- ReclassedLCDBV5 %>% select(SrinivasanLandUse) %>% group_by(SrinivasanLandUse) %>% summarise()

#GISUnion the reclassed LCDBV5 with the Dairy areas
LandUsePlusDairy <- GISunion(ReclassedLCDBV5,Dairy)

#LCDV5 pasture is considered Sheep and Beef unless Monaghan thinks it's Dairy
LandUsePlusDairy$SrinivasanLandUse[LandUsePlusDairy$SrinivasanLandUse == "Pasture"] <- "Sheep and Beef"
LandUsePlusDairy$SrinivasanLandUse[!is.na(LandUsePlusDairy$Dairy)] <- "Dairy"

plot(LandUsePlusDairy[,"SrinivasanLandUse"],border=NA, key.width = lcm(4.5))

#Rename te columns prior to saving, otherwise the ESRI driver will shorten them to 8 letters using its own system
LandUsePlusDairy <- LandUsePlusDairy %>% rename(LandUse = SrinivasanLandUse)

LandUsePlusDairy %>% st_write(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "LandUse", delete_layer = TRUE)

End_Time = Sys.time()
End_Time - Start_time

#Clear out some more space
remove("MonaghanDairy","LCDBV5","LandUse","LandUsePlusDairy")

```

Now need to do slope
```{r,eval = FALSE}
#Takes 2 minutes
Start_time = Sys.time()

#The LRI Slope geodatabase. version  from downloaded from LRIS
#Better to get the GeoPackage version as that is an Open data format.
LRIGeoDatabase <- "D:\\Projects\\data\\LRI\\Slope\\nzlri-slope.gdb"
LRISlope <- sf::st_read(LRIGeoDatabase)

SlopeLookupTable <- read.csv(file.path(ProjectDataDirectory,"LRISlopeReclassTable.csv"))

LRISlope <- merge(LRISlope,SlopeLookupTable[,c("LRI..SLOPE1S..Class.ID","Srinivasan.slope.type")],
                  by.x = "SLOPE1S",by.y = "LRI..SLOPE1S..Class.ID",all.x=TRUE)
LRISlope$Srinivasan.slope.type[is.na(LRISlope$Srinivasan.slope.type)] <- "Flat"
Slope <- LRISlope %>% select(Srinivasan.slope.type) %>% group_by(Srinivasan.slope.type) %>% summarise()
#st_write(Slope,dsn = file.path(GISDirectory,"Slope"),driver = "ESRI Shapefile",append = FALSE)
Slope %>% st_write(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "Slope", delete_layer = TRUE)

#Plot the result as a check it is right
plot(Slope[,"Srinivasan.slope.type"],border=NA, key.width = lcm(4.5))

End_Time = Sys.time()
End_Time - Start_time

#Clear out some more space
remove("LRISlope","Slope")
```

Now do  moisture
```{r,eval = FALSE}
#Takes 45 seconds
Start_time = Sys.time()

#The MfE Irrigated area geodatabase. version downloaded from MfE Data portal 
IrrigationGeoDatabase <- "D:\\Projects\\data\\MfE\\Irrigation\\irrigated-land-area-raw-2020-update.gdb"
Irrigation<- sf::st_read(IrrigationGeoDatabase)

#Fix any issues with the geometry
Irrigation <- st_make_valid(Irrigation)

#Create an attribute explicitly set to TRUE useful for the later union with the rain data
Irrigation$Irrigated <- TRUE
Irrigation <- Irrigation[,c("Irrigated")]

#Merge all the adjoining polygons together takes 30 s. Do not convert from  MultiPolygons to Polygons as this stops my GISUnion function from working
Irrigation <- Irrigation %>% select(Irrigated) %>% group_by(Irrigated) %>% dplyr::summarise()

#Prepare the rain data
RainfallFile <- "D:\\Projects\\data\\MfE\\Rain19722016\\totann7216.tif" #Note that this is in NZMG projection.

RainfallRaster <- rast(RainfallFile)

#Reclassify <1100, 1100-1700, >1700
RainReclassMatrix <- matrix(c(0,1100,1,
                       1100,1700,2,
                       1700,30000,3), ncol=3, byrow=TRUE)
ClassifiedRain <- classify(RainfallRaster, rcl = RainReclassMatrix, include.lowest = TRUE)

#Convert to polygons
PolygonisedRain <- sf::st_as_sf(as.polygons(ClassifiedRain))
PolygonisedRain <- st_make_valid(PolygonisedRain)
#Reproject to NZTM
PolygonisedRain <- st_transform(PolygonisedRain, crs=2193)
PolygonisedRain$Srinivasan.Moisture.Type <- c("Dry","Moist","Wet")[PolygonisedRain$totann7216]

#Union with irrigation takes time.. about a minute....
Moisture <- GISunion(PolygonisedRain,Irrigation)

#Set all Irrigated polygons to have a moisture class of "Irrigated"
Moisture$Srinivasan.Moisture.Type[Moisture$Irrigated] <- "Irrigated"

#st_write(Moisture,dsn = file.path(GISDirectory,"Moisture"),driver = "ESRI Shapefile",append = FALSE)
Moisture %>% st_write(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "Moisture", delete_layer = TRUE)

plot(Moisture[,"Srinivasan.Moisture.Type"],border=NA, key.width = lcm(4.5))

End_Time = Sys.time()
End_Time - Start_time

#Clear out some space
remove("Irrigation","RainfallRaster","PolygonisedRain","Moisture")
```

Load a catchment, intersect the land use, slope and moisture
Lookup the srinivasan TP and TN
Calculate total TP and TN, as well as contributions from each land use type
Provide totals and contributions of nutrients, as well as area.
```{r}
#Load the Srinivasan Land Use, Moisture and Slope type's spatial data
LandUse <- st_read(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "LandUse")
Slope <- st_read(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "Slope")
Moisture <- st_read(file.path(GISDirectory,"SrinivasanTypes.gpkg"),layer = "Moisture")

#Load the catchment spatial data
Catchments <- st_read(dsn = file.path(GISDirectory,"Catchments","Catchments.shp"))

#Load the nutrient loss rate coefficient look-up data
NutrientLookupTable <- read.csv(LeachRateLUTFile)

Start_Time = Sys.time()
#Initialise an empty output dataframe
NutrientOutputData       <- data.frame(NULL)
FarmScaleMetadata        <- data.frame(NULL)
CatchmentScaleMetadata   <- data.frame(NULL)
WaterQualitySiteMetadata <- data.frame(NULL)


#work through each catchment using a for loop as the apply doesn't work well with sf objects
#For all Catchments this takes 3 Hours!!
for (WaterQualitySite in Catchments$sID[1] ){
  Catchment <- Catchments[Catchments$sID == WaterQualitySite,]
  CatchmentArea <- st_area(Catchment) %>% units::set_units(NULL) / 10000
  
  WaterQualitySiteMetadata <- data.frame("sID"=Catchment$sID,
                                         "Hectares"=CatchmentArea,
                                         "nzsegment"=Catchment$nzsegment)

  #Subset and intersect the Srinivasan spatial data to just the catchment.
  #Seems to need removal of any existing CatchmentLandUse object before it is re-created
  rm(CatchmentLandUse)
  
  #Note that the intersections raise a warning:
  #"attribute variables are assumed to be spatially constant throughout all geometries"
  #This can be suppressed (see https://github.com/r-spatial/sf/issues/406)
  #By explicitly defining the attributes of the contributing geometries as constant
  #Or by only intersecting the geometries, then -re-attaching the attributes
  #I don't understand this and need to figure out what is meant.
  #But I think I can do the explicit solution.
  CatchmentLandUse <- st_intersection(Catchment,LandUse)
  CatchmentLandUseSlope <- st_intersection(CatchmentLandUse,Slope)
  CatchmentLandUseSlopeMoisture <- st_intersection(CatchmentLandUseSlope,Moisture)
  
  #Get the area of each typology and set the units to hectares, but clear the units attribute to avoid managing units later on
  CatchmentLandUseSlopeMoisture$area.ha <- st_area(CatchmentLandUseSlopeMoisture) %>% units::set_units(NULL)  / 10000

  #Use the look up table to define TP and TN for each srinivasan class
  CatchmentLandUseSlopeMoisture <- merge(CatchmentLandUseSlopeMoisture,NutrientLookupTable,by.x = c("Srinivasan.slope.type","Srinivasan.Moisture.Type","LandUse"),by.y = c("Slope","Moisture","LandUse"))
  
  #About here, convert to a high resolution raster of TN, TP and Srinivasan class
  # Then use 
  
#Ditch the geometry to make further processing easier
  rm(CatchmentData)
  CatchmentData <- st_drop_geometry(CatchmentLandUseSlopeMoisture)
  
  #Calculate load for each polygon
  CatchmentData$TN.Load <- CatchmentData$TN.Loss.Rate * CatchmentData$area.ha
  CatchmentData$TP.Load <- CatchmentData$TP.Loss.Rate * CatchmentData$area.ha

  #Group and summarise on Land Use
  CatchmentLandUseData <- CatchmentData %>% group_by(LandUse) %>% 
    summarise(areaPct = sum(area.ha)/CatchmentArea,area.ha = sum(area.ha),sID = first(sID),nzsegment=first(nzsegment),
              TN = sum(TN.Load)/sum(area.ha),TP = sum(TP.Load)/sum(area.ha))
  

  CatchmentWide <- pivot_wider(CatchmentLandUseData,
                               id_cols = c(sID,nzsegment),
                               names_from=LandUse,
                               values_from = c(area.ha,TN,TP),
                               names_glue = "{LandUse}_{.value}")
  
  CatchmentWide$area.ha <- CatchmentArea
  CatchmentWide$TNLoad <- sum(CatchmentData$TN.Load)
  CatchmentWide$TPLoad <- sum(CatchmentData$TP.Load)
  CatchmentWide$TNLossRate <- (CatchmentWide$TNLoad / CatchmentArea) 
  CatchmentWide$TPLossRate <- (CatchmentWide$TPLoad / CatchmentArea) 
  
  #Calculate total area, TN and TP
  #CatchmentWide$TotalArea <- 
    
    #Calculate %area for each land use
  
  NutrientOutputData <- dplyr::bind_rows(NutrientOutputData,CatchmentWide)
  #write to a csv file

}
End_Time = Sys.time()
End_Time - Start_Time

write.table(NutrientOutputData,file=file.path(ProjectDataDirectory,"Output.csv"),sep=",",row.names = FALSE,append=TRUE,quote = FALSE)
```



